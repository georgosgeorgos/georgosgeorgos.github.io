<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link rel="icon" href="./assets/me.png">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        a {
            color: #228b22;
            text-decoration: none;
        }

        a:focus,
        a:hover {
            color: #f09228;
            text-decoration: none;
        }

        body,
        td,
        th,
        tr,
        p,
        a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 22px;
        }

        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
            font-weight: 700
        }

        name {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
        }

        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }

        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        span.highlight {
            background-color: #ffffd0;
        }

        .new {
            background-color: #cc0000;
            color: white;
            border-radius: 5px;
            padding: 1px;
            font-size: 14px;
            margin: 0 5px;
        }
    </style>
    <link rel="icon" type="image/png" href="http://www.linkedin.com/in/giorgio-c-giannone/">

    <title>Giorgio Giannone</title>

    <link href="./css" rel="stylesheet" type="text/css">

</head>

<body data-gr-c-s-loaded="true">
    <table width="840" border="0" align="center" cellspacing="0" cellpadding="0">
        <tbody>
            <tr>
                <td>
                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td width="67%" valign="middle">
                                    <p align="center">
                                        <name>Giorgio Giannone</name>
                                    </p>
                                    <br>

                                    <!-- ######## ABSTRACT #########-->
                                    <p>I am a PhD student at the <a
                                            href="https://www.compute.dtu.dk/english/research/research-sections/cogsys"
                                            target="_blank">Section for Cognitive Systems</a> at the Technical
                                        University of Denmark (<a href="https://www.compute.dtu.dk/english"
                                            target="_blank">DTU</a>),
                                        supervised by <a
                                            href="https://scholar.google.com/citations?user=7VAwhzUAAAAJ&hl=en"
                                            target="_blank">Ole Winther</a> and
                                        <a href="http://www2.compute.dtu.dk/~sohau/" target="_blank">S&oslashren
                                            Hauberg</a>.
                                    </p>
                                    <!-- ######## INFO  #########-->
                                    <!-- <p align="center">
                                        <a href=""  target="_blank"><img src="./assets/logos/gaia_logo.jpeg" alt="blind-date" width="10%"></a>
                                    </p> -->
                                    <p align="center">
                                        <a href="https://www.dima.uniroma1.it/dima/en"
                                            href="http://datascience.i3s.uniroma1.it/it" target="_blank"><img
                                                src="./assets/logos/sapienza_logo.jpeg" alt="blind-date"
                                                width="10%"></a>
                                        <a href="https://engineering.nyu.edu" target="_blank"><img
                                                src="./assets/logos/nyu_logo.jpeg" alt="blind-date" width="10%"></a>
                                        <a href="https://www.compute.dtu.dk" target="_blank"><img
                                                src="./assets/logos/dtu_logo_red.jpeg" alt="blind-date" width="10%"></a>
                                        <a href="https://engineering.mit.edu" target="_blank"><img
                                                src="./assets/logos/mit_logo.jpeg" alt="blind-date" width="10%"></a>
                                        <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-new-england/"
                                            target="_blank"><img src="./assets/logos/msft_logo.png" alt="blind-date"
                                                width="10%"></a>
                                        <a href="https://www.zurich.ibm.com" target="_blank"><img
                                                src="./assets/logos/ibm_logo.jpeg" alt="blind-date" width="10%"></a>
                                        <a href="https://www.amazon.science" target="_blank"><img
                                                src="./assets/logos/amazon_logo.jpeg" alt="blind-date" width="10%"></a>
                                        <a href="https://nnaisense.com" target="_blank"><img
                                                src="./assets/logos/nnaisense_logo.jpeg" alt="blind-date"
                                                width="10%"></a>
                                        <a href="https://europe.naverlabs.com" target="_blank"><img
                                                src="./assets/logos/naver_labs_logo.jpeg" alt="blind-date"
                                                width="10%"></a>
                                        <!-- <a href=""  target="_blank"><img src="./assets/logos/gaia_logo.jpeg" alt="blind-date" width="10%"></a> -->

                                    </p>
                                    <br>
                                    <p align="center">
                                        <!-- <a href="mailto:gigi%3Cat%3Edtu%3Cdot%3Edk" target="_blank">Email</a> &nbsp;/&nbsp; -->
                                        <!-- <a href="mailto:giorgio%3Cdot%3Ec%3Cdot%3Egiannone%3Cat%3Egmail%3Cdot%3Ecom" target="_blank">Email</a> &nbsp;/&nbsp; -->
                                        <a href="./assets/cv/giorgio_giannone_cv.pdf" target="_blank">CV</a>
                                        &nbsp;/&nbsp;
                                        <a href="https://github.com/georgosgeorgos" target="_blank">GitHub</a>
                                        &nbsp;/&nbsp;
                                        <a href="http://www.linkedin.com/in/giorgio-c-giannone/" target="_blank">
                                            LinkedIn </a> &nbsp;/&nbsp;
                                        <a href="https://scholar.google.com/citations?user=1qsJQhkAAAAJ&hl=en"
                                            target="_blank">Scholar</a>
                                        <!-- <a href="https://twitter.com/georgosgeorgos" target="_blank">Twitter</a> -->
                                        <!-- <a href="./blog/index.html">Blog</a> -->
                                    </p>
                                </td>
                                <td width="33%">
                                    <a href="http://www.linkedin.com/in/giorgio-c-giannone/" target="_blank"><img
                                            src="./assets/me2.jpg" width="70%"
                                            style="border-radius: 10px 10px 10px 10px"></a>
                                    <!-- <figcaption align="left">The one on my right.</figcaption> -->
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <!-- ######## NEWS  #########-->

                    <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td width="100%" valign="middle">
                                    <heading id="news">News</heading>
                                    <ul>
                                        <li>Aug 2020: I will present a poster at <a href="https://smiles.skoltech.ru/school" target="_blank">SMILES2020</a>.
                            </li>
                            <li>July 2020: I presented a poster at <a href="https://www.eeml.eu/" target="_blank">EEML2020</a>.
                            </li>
                    <li>June 2020: Starting <a href="https://www.compute.dtu.dk/english/research/research-sections/cogsys"
                                                target="_blank">PhD</a>!
                                        </li>
                                        <li>Apr 2020: Extended preprint for <a href="https://arxiv.org/abs/1912.03845" target="_blank">No Representation without
                                                Transformation</a> on arXiv.
                                        </li>
                                        <li>Oct 2019: Paper accepted at <a href="http://bayesiandeeplearning.org/" target="_blank">BDL</a>
                                            and <a href="https://pgr-workshop.github.io/accepted_papers/" target="_blank">PGR</a> workshops at NeurIPS 2019.
                                        </li>
                                        <li>Apr 2019: Paper accepted at <a href="https://mula-workshop.github.io/" target="_blank">MULA</a> workshop at CVPR
                                            2019.
                                        </li>
                                        <li>Jan 2019: Starting an internship at <a href="https://nnaisense.com" target="_blank">NNAISENSE</a>.
                                        </li>
                                        <li>Oct 2018: <a href="http://datascience.i3s.uniroma1.it/it" target="_blank">MSc</a> Graduation!
                                        </li>
                                        <li>Mar 2018: Starting an internship at <a href="https://europe.naverlabs.com/" target="_blank">Naver Labs Europe</a>.
                                        </li>
                                        <li>Aug 2017: Starting a visiting period at <a href="https://vida.engineering.nyu.edu/" target="_blank">New York
                                                University</a>.
                                        </li>
                                        </li>
                                    </ul>
                                </td>
                            </tr>
                        </tbody>
                    </table> -->

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td width="100%" valign="middle">
                                    <p>
                                        <em>
                                            I am broadly interested in Probabilistic Machine Learning, Perception and
                                            Geometry, <br>
                                            with a focus on Conditional Diffusion Models, Language Models Adaptation, Few-Shot Generation, <br>and Hierarchical Variational
                                            Inference.
                                        </em>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <!-- RESEARCH -->
                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td width="100%" valign="middle">
                                    <heading id="research">Research</heading>
                                    <p>
                                        I am interested in the generalization and adaptation capacities of hierarchical
                                        generative models.<br> <br>
                                        Large generative models trained on millions of data points exhibit emergent
                                        adaptation properties like in-context learning, being able to solve novel tasks
                                        given a handful of samples.
                                        However, such adaptation properties emerge only with scale, being absent for
                                        middle-size models trained on small datasets,
                                        a typical scenario in engineering design and scientific discovery, where data
                                        collection is expensive and computational constraints are present.<br> <br>
                                        My research goal is to bridge the gap in adaptation capabilities between large
                                        and middle-size generative models.
                                        Leveraging the tools of hierarchical inference and using the training dataset to encourage adaptation at inference time,
                                        we can learn expressive families of conditional generative processes and perform
                                        few-shot generation and transfer learning in the small data and model regime.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <!-- ######## PAPERS #########-->


                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>In Progress</heading>
                                </td>

                            </tr>
                        </tbody>
                        <tbody>
                            <tr>
                                <td width="25%"><img src="./assets/images/invalid2valid.png" alt="blind-date"
                                        width="90%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="" target="_blank">
                                            <papertitle>Improving Precision in Language Models Learning from Invalid
                                                Samples
                                            </papertitle>
                                        </a>
                                        <br>
                                        <a href="https://github.com/jakob949">Niels Jakob Larsen*</a>,
                                        <strong>Giorgio Giannone</strong>*,
                                        <a href="https://olewinther.github.io/" target="_blank">Ole Winther</a>,
                                        <a href="https://orbit.dtu.dk/en/persons/kai-kristof-blin" target="_blank">Kai
                                            Blin</a>
                                        <br>
                                        <em>Generative AI and Biology Workshop, NeurIPS</em>, 2023
                                        <br>
                                    </p>
                                    Language Models are powerful generative tools capable of learning intricate patterns
                                    from vast amounts of unstructured data. Nevertheless, in domains that demand
                                    precision, such as science and engineering, the primary objective is to obtain an
                                    exact and accurate answer. Precision takes precedence in these contexts. In
                                    specialized tasks like chemical compound generation, the emphasis is on output
                                    accuracy rather than response diversity. Traditional self-refinement methods are
                                    ineffective for such domain-specific input/output pairs, unlike general language
                                    tasks. In this study, we introduce invalid2valid, a powerful and general
                                    post-processing mechanism that can significantly enhance precision in language
                                    models for input/output tasks spanning different domains and specialized
                                    applications.
                                    <p>

                                    </p>
                                </td>
                            </tr>


                            <tr>
                                <td width="25%"><img src="./assets/images/align_adapt_llm_bio.png" alt="blind-date"
                                        width="90%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="" target="_blank">
                                            <papertitle>Enhancing Language Models for Technical Domains with Dynamic
                                                Token Injection
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://www.microsoft.com/en-us/research/people/netenenh/"
                                            target="_blank">Neil Tenenholtz</a>,
                                        <a href="https://www.microsoft.com/en-us/research/people/jamhall/"
                                            target="_blank">James Hall</a>,
                                        <a href="http://nicolofusi.com" target="_blank">Nicolo Fusi</a>,
                                        <a href="https://dmelis.github.io" target="_blank">David Alvarez-Melis</a>
                                        <br>
                                        <em>Generative AI and Biology Workshop, NeurIPS</em>, 2023
                                        <br>
                                    </p>
                                    Large language models (LLMs) are rapidly advancing the frontier of natural language
                                    understanding and generation. Their generalist nature, while adept at handling a
                                    wide range of tasks, often lacks the depth and precision required by highly
                                    specialized and rapidly evolving technical domains, such as genomics and engineering
                                    design. Fine-tuning these models for specific domains can be effective but requires
                                    large amounts of data and compromises their general reasoning capabilities. In this
                                    work, we introduce a scalable method to infuse specialized knowledge into generalist
                                    language models by dynamically extending their vocabulary with specialist tokens. By
                                    using a lightweight functional mapping on an extended vocabulary and adjusting the
                                    logit distribution, we enable the model to grasp domain-specific nuances.
                                    <p>

                                    </p>
                                </td>
                            </tr>
                        </tbody>


                        <tbody>
                            <tr>
                                <td>
                                    <heading>Publications</heading>
                                </td>

                            </tr>
                        </tbody>
                        <tbody>


                            <tr>
                                <td width="25%"><img src="./assets/images/ta.png" alt="blind-date" width="90%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/2305.18470" target="_blank">
                                            <papertitle>Aligning Optimization Trajectories with Diffusion Models for
                                                Constrained Design Generation
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://akashgit.github.io" target="_blank">Akash Srivastava</a>,
                                        <a href="https://olewinther.github.io/" target="_blank">Ole Winther</a>,
                                        <a href="https://meche.mit.edu/people/faculty/faez@MIT.EDU" target="_blank">Faez
                                            Ahmed</a>
                                        <br>
                                        <em>Neural Information Processing Systems, NeurIPS</em>, 2023
                                        <br>
                                    </p>
                                    <p>
                                        Generative models have had a profound impact on vision and language, paving the
                                        way for a new era of multimodal generative applications.
                                        While these successes have inspired researchers to explore using generative
                                        models in science and engineering to accelerate the design process and reduce
                                        the reliance on iterative optimization, challenges remain.
                                        Specifically, engineering optimization methods based on physics still outperform
                                        generative models when dealing with constrained environments where data is
                                        scarce and precision is paramount.
                                        To address these challenges, we introduce Diffusion Optimization Models (DOM)
                                        and Trajectory Alignment (TA),
                                        a learning framework that demonstrates the efficacy of aligning the sampling
                                        trajectory of diffusion models with the optimization trajectory derived from
                                        traditional physics-based methods.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/csgm.png" alt="blind-date" width="90%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/2306.15166" target="_blank">
                                            <papertitle>Learning from Invalid Data: On Constraint Satisfaction in
                                                Generative Models
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>*,
                                        <a href="https://scholar.google.com/citations?user=MQ9nKDsAAAAJ&hl=en"
                                            target="_blank">Lyle Regenwetter*</a>,
                                        <a href="https://akashgit.github.io" target="_blank">Akash Srivastava*</a>,
                                        <a href="https://research.ibm.com/people/dan-gutfreund" target="_blank">Dan
                                            Gutfreund</a>,
                                        <a href="https://meche.mit.edu/people/faculty/faez@MIT.EDU" target="_blank">Faez
                                            Ahmed</a>
                                        <br>
                                        <em>Diffusion Models Workshop, NeurIPS</em>, 2023
                                        <br>
                                    </p>
                                    <p>
                                        Generative models have demonstrated impressive results in vision, language, and
                                        speech.
                                        However, even with massive datasets, they struggle with precision, generating
                                        physically invalid or factually incorrect data.
                                        This is particularly problematic when the generated data must satisfy
                                        constraints, for example, to meet product specifications in engineering design
                                        or to adhere to the laws of physics in a natural scene.
                                        To improve precision while preserving diversity and fidelity, we propose a novel
                                        training mechanism that leverages datasets of constraint-violating data points,
                                        which we consider invalid.
                                    </p>
                                </td>
                            </tr>


                            <tr>
                                <td width="25%"><img src="./assets/images/mdmt-clm.png" alt="blind-date" width="90%">
                                </td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/2301.12586" target="_blank">
                                            <papertitle>Unifying Molecular and Textual Representations via Multi-task
                                                Language Modelling
                                            </papertitle>
                                        </a>
                                        <br>
                                        <a href="https://researcher.watson.ibm.com/researcher/view.php?person=zurich-DIC"
                                            target="_blank">Dimitrios Christofidellis</a>*,
                                        <strong>Giorgio Giannone</strong>*,
                                        <a href="https://research.ibm.com/people/jannis-born" target="_blank">Jannis
                                            Born</a>,
                                        <a href="https://olewinther.github.io/" target="_blank">Ole Winther</a>,
                                        <a href="https://research.ibm.com/people/teodoro-laino" target="_blank">Teodoro
                                            Laino</a>,
                                        <a href="https://research.ibm.com/people/matteo-manica" target="_blank">Matteo
                                            Manica</a>
                                        <br>
                                        <em>International Conference on Machine Learning, ICML</em>, 2023
                                        <br>
                                    </p>
                                    <p>
                                        The recent advances in neural language models have also been successfully
                                        applied to the field of chemistry,
                                        offering generative solutions for classical problems in molecular design and
                                        synthesis planning. These new methods have the potential to optimize laboratory
                                        operations and fuel
                                        a new era of data-driven automation in scientific discovery. However,
                                        specialized models are still typically required for each task, leading to the
                                        need for problem-specific
                                        fine-tuning and neglecting task interrelations. Here, we propose a
                                        multi-domain, multi-task language model to solve a wide range of tasks in both
                                        the chemical and natural
                                        language domains. By leveraging multi-task learning, our model can handle
                                        chemical and natural language concurrently, without requiring expensive
                                        pre-training on single
                                        domains or task-specific models.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/todm.png" alt="blind-date" width="90%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/2303.09760" target="_blank">
                                            <papertitle>Diffusing the Optimal Topology: A Generative Optimization
                                                Approach
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://meche.mit.edu/people/faculty/faez@MIT.EDU" target="_blank">Faez
                                            Ahmed</a>
                                        <br>
                                        <em>International Design Engineering Technical Conferences, IDETC</em>, 2023
                                        <br>
                                    </p>
                                    <p>
                                        Topology Optimization seeks to find the best design that satisfies a set of
                                        constraints while maximizing system performance.
                                        Traditional iterative optimization methods like SIMP can be computationally
                                        expensive and get stuck in local minima,
                                        limiting their applicability to complex or large-scale problems.
                                        Recently, deep generative models, such as Generative Adversarial
                                        Networks and Diffusion Models,
                                        conditioned on constraints and physics fields have shown promise, but they
                                        require extensive pre-processing and surrogate models for improving performance.
                                        To address these issues, we propose a Generative Optimization method that
                                        integrates classic optimization like SIMP as a refining mechanism for the
                                        topology generated by a deep generative model.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/gt4sd_npj.png" alt="blind-date" width="70%">
                                </td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://www.nature.com/articles/s41524-023-01028-1" target="_blank">
                                            <papertitle>Accelerating material design with the generative toolkit for
                                                scientific discovery
                                            </papertitle>
                                        </a>
                                        <br>
                                        <a href="https://gt4sd.github.io/gt4sd-core/" target="_blank">Manica & the GT4SD
                                            Team (Core Contributor)</a>
                                        <br>
                                        <em>Nature npj Computational Materials</em>, 2023
                                        <br>
                                    </p>
                                    With the growing availability of data within various scientific domains,
                                    generative models hold enormous potential to accelerate scientific discovery.
                                    They harness powerful representations learned from datasets to speed up the
                                    formulation
                                    of novel hypotheses with the potential to impact material discovery broadly.
                                    We present the Generative Toolkit for Scientific Discovery (GT4SD).
                                    This extensible open-source library enables scientists, developers,
                                    and researchers to train and use state-of-the-art generative models
                                    to accelerate scientific discovery focused on organic material design.
                                    <p>

                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/fsdm.png" alt="blind-date" width="70%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/2205.15463" target="_blank">
                                            <papertitle>Few-Shot Diffusion Models
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://didriknielsen.github.io/" target="_blank">Didrik Nielsen</a>,
                                        <a href="https://olewinther.github.io/" target="_blank">Ole Winther</a>
                                        <br>
                                        <em>Score-Based Methods Workshop, NeurIPS</em>, 2022
                                        <br>
                                    </p>
                                    <p>
                                        Denoising diffusion probabilistic models (DDPM) are powerful hierarchical latent
                                        variable models with remarkable sample generation quality and training
                                        stability.
                                        These properties can be attributed to parameter sharing in the generative
                                        hierarchy, as well as a parameter-free diffusion-based inference procedure.
                                        In this paper, we present Few-Shot Diffusion Models (FSDM), a framework for
                                        few-shot generation leveraging conditional DDPMs.
                                        FSDMs are trained to adapt the generative process conditioned on a small set of
                                        images from a given class by aggregating image patch information using a
                                        set-based Vision Transformer (ViT).
                                        At test time, the model is able to generate samples from previously unseen
                                        classes conditioned on as few as 5 samples from that class.
                                        We empirically show that FSDM can perform few-shot generation and transfer to
                                        new datasets taking full advantage of the conditional DDPM.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/scha-vae.png" alt="blind-date" width="90%">
                                </td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/2110.12279" target="_blank">
                                            <papertitle>SCHA-VAE: Hierarchical Context Aggregation for
                                                Few-Shot Generation
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://olewinther.github.io/" target="_blank">Ole Winther</a>
                                        <br>
                                        <em>International Conference on Machine Learning, ICML</em>, 2022
                                        <br>
                                    </p>
                                    <p>A few-shot generative model should be able to generate data from a novel
                                        distribution by only observing a limited set of examples.
                                        In few-shot learning the model is trained on data from many sets from
                                        distributions sharing some underlying properties such
                                        as sets of characters from different alphabets or objects from different
                                        categories.
                                        We extend current latent variable models for sets to a fully hierarchical
                                        approach with an attention-based point to
                                        set-level aggregation and call our method SCHA-VAE for
                                        Set-Context-Hierarchical-Aggregation Variational Autoencoder.
                                        We explore likelihood-based model comparison, iterative data sampling, and
                                        adaptation-free out-of-distribution generalization.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/jm1_bar.png" alt="blind-date" width="90%">
                                </td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/2210.12195" target="_blank">
                                            <papertitle>Just Mix Once: Worst-group Generalization by Group
                                                Interpolation
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://serhii-havrylov.github.io/" target="_blank">Serhii
                                            Havrylov</a>,
                                        <a href="https://uk.linkedin.com/in/jordan-massiah-562862136"
                                            target="_blank">Jordan Massiah</a>,
                                        <a href="https://sites.google.com/site/emineyilmaz/home" target="_blank">Emine
                                            Yilmaz</a>,
                                        <a href="https://yunlongjiao.github.io/" target="_blank">Yunlong Jiao</a>
                                        <br>
                                        <em>Distribution Shifts Workshop, NeurIPS</em>, 2021
                                        <br>
                                    </p>
                                    <p>
                                        Advances in deep learning theory have revealed how average generalization relies
                                        on superficial patterns in data.
                                        The consequences are brittle models with poor performance with shift in group
                                        distribution at test time.
                                        When group annotation is available, we can use robust optimization tools to
                                        tackle the problem.
                                        However, identification and annotation are time-consuming, especially on large
                                        datasets.
                                        A recent line of work leverages self-supervision and oversampling to improve
                                        generalization on minority groups
                                        without group annotation. We propose to unify and generalize these approaches
                                        using a class-conditional variant
                                        of mixup tailored for worst-group generalization. Our approach, Just Mix Once
                                        (JM1),
                                        interpolates samples during learning, augmenting the training distribution with
                                        a continuous mixture of groups.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/hfsgm.png" alt="blind-date" width="90%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://openreview.net/forum?id=INSai0E0VXN" target="_blank">
                                            <papertitle>Hierarchical Few-Shot Generative Models
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://olewinther.github.io/" target="_blank">Ole Winther</a>
                                        <br>
                                        <em>Meta-Learning Workshop, NeurIPS</em>, 2021
                                        <br>
                                    </p>
                                    <p>A few-shot generative model should be able to generate data from a distribution
                                        by only observing a limited set of examples. In few-shot learning the model is
                                        trained on data from many sets from different distributions sharing some
                                        underlying
                                        properties such as sets of characters from different alphabets or sets of images
                                        of different type objects. We study a latent variables approach that extends the
                                        Neural Statistician to a fully hierarchical approach with an attention-based
                                        point to set-level aggregation. We extend the previous work to iterative data
                                        sampling,
                                        likelihood-based model comparison, and adaptation-free out of distribution
                                        generalization.
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/gm_all.png" alt="blind-date" width="90%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="./assets/report/tauvae.pdf" target="_blank">
                                            <papertitle>Transformation-aware Variational Autoencoder
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://simons.berkeley.edu/people/saeed-saremi" target="_blank">Saeed
                                            Saremi</a>,
                                        <a href="https://people.lu.usi.ch/mascij/" target="_blank">Jonathan Masci</a>,
                                        <a href="https://osdf.github.io/" target="_blank">Christian Osendorfer</a>
                                        <br>
                                        <em>Technical Report</em>, 2020
                                        <br>
                                    </p>
                                    <p>We extend the framework of variational autoencoders to represent transformations
                                        explicitly in the latent space. This is achieved in the form of a generative
                                        model
                                        structured such that the group of transformations
                                        that act in the input space is instead represented by latent variables
                                        which are linear operators that only act in the latent space.
                                        In the family of hierarchical graphical models that emerges,
                                        the latent space is populated by higher order objects which are inferred
                                        jointly with the latent representations they act on.</p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/pipeline.png" alt="blind-date" width="90%">
                                </td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/2004.03156" target="_blank">
                                            <papertitle>Real-time Classification from Short Event-Camera Streams using
                                                Input-filtering Neural ODEs
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="http://ashaanoosheh.com/" target="_blank">Asha Anoosheh</a>,
                                        <a href="https://www.linkedin.com/in/aqua83/?originalSubdomain=ch"
                                            target="_blank">Alessio Quaglino</a>,
                                        <a href="https://proceduralia.github.io/" target="_blank">Pierluca D'Oro</a>,
                                        <a href="http://marcogallieri.micso.it/Home.html" target="_blank">Marco
                                            Gallieri</a>,
                                        <a href="https://people.lu.usi.ch/mascij/" target="_blank">Jonathan Masci</a>
                                        <br>
                                        <em>Interpretable Inductive Biases
                                            and Physically Structured Learning Workshop, NeurIPS</em>, 2020
                                        <br>
                                    </p>
                                    <p>Event-based cameras are novel, efficient sensors inspired by the human vision
                                        system,
                                        generating an asynchronous, pixel-wise stream of data.
                                        Learning from such data is generally performed through heavy preprocessing and
                                        event integration into images.
                                        This requires buffering of possibly long sequences and can limit the response
                                        time of the inference system.
                                        In this work, we instead propose to directly use events from a DVS camera,
                                        a stream of intensity changes and their spatial coordinates.
                                        This sequence is used as the input for a novel asynchronous RNN-like
                                        architecture,
                                        the Input-filtering Neural ODEs.</p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/knn.png" alt="blind-date" height="100"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/1912.03845v1" target="_blank">
                                            <papertitle>No Representation without Transformation
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://people.lu.usi.ch/mascij/" target="_blank">Jonathan Masci</a>,
                                        <a href="https://osdf.github.io/" target="_blank">Christian Osendorfer</a>
                                        <br>
                                        <em>Bayesian Deep Learning and Perception as Generative Reasoning Workshops,
                                            NeurIPS </em>, 2019
                                        <br>
                                    </p>
                                    <p>We propose to extend Latent Variable Models with a simple idea:
                                        learn to encode not only samples but also transformations of such samples.
                                        This means that the latent space is not only populated by embeddings
                                        but also by higher order objects that map between these embeddings.
                                        We show how a hierarchical graphical model can be utilized to enforce
                                        desirable algebraic properties of such latent mappings.</p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/common.png" alt="blind-date" width="90%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://arxiv.org/abs/1812.06873" target="_blank">
                                            <papertitle>Learning Common Representation from RGB and Depth Images
                                            </papertitle>
                                        </a>
                                        <br>
                                        <strong>Giorgio Giannone</strong>,
                                        <a href="https://europe.naverlabs.com/people_user/Boris-Chidlovskii/"
                                            target="_blank">Boris Chidlovskii</a>
                                        <br>
                                        <em>Multimodal Learning and Applications Workshop, CVPR</em>, 2019
                                        <br>
                                    </p>
                                    <p>We propose a new deep learning architecture for the tasks of semantic
                                        segmentation
                                        and depth prediction from RGB-D images.
                                        We revise the state of art based on the RGB and depth feature fusion,
                                        where both modalities are assumed to be available at train and test time.
                                        We propose a new architecture where the feature fusion is replaced with a common
                                        deep representation.
                                        Combined with an encoder-decoder type of the network, the architecture can
                                        jointly learn models
                                        for semantic segmentation and depth estimation based on their common
                                        representation.</p>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Open-source</heading>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>

                            <tr>
                                <td width="25%"><img src="./assets/images/gt4sd_overview.png" alt="blind-date"
                                        width="100%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://github.com/GT4SD/gt4sd-core" target="_blank">
                                            <papertitle>GT4SD: Generative Toolkit for Scientific Discovery
                                            </papertitle>
                                        </a>
                                        <br>
                                        <a href="https://github.com/GT4SD/gt4sd-core/graphs/contributors?from=2022-02-06&to=2022-11-24&type=c"
                                            target="_blank">
                                            GT4SD Team, 2022
                                        </a>
                                        <br>
                                        <br>
                                    </p>
                                    <p>The GT4SD (Generative Toolkit for Scientific Discovery) is an open-source
                                        platform to accelerate hypothesis generation in the scientific discovery
                                        process. It provides a library for making state-of-the-art generative AI models
                                        easier to use.</p>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Datasets</heading>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>

                            <tr>
                                <td width="25%"><img src="./assets/images/256_optimized.png" alt="blind-date"
                                        width="100%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="" target="_blank">
                                            <papertitle>2d Topology Optimization
                                            </papertitle>
                                        </a>
                                        <br>
                                    </p>
                                    <p>We built a dataset of optimized topologies and intermediate optimization steps at
                                        low-resolution (64x64) and
                                        high-resolution (256x256) with constraints.
                                    <ul>
                                        <li>50K low-resolution optimized topologies.</li>
                                        <li>60K high-resolution optimizer topologies.</li>
                                        <li>250K low-resolution intermediate steps.</li>
                                        <li>300K high-resolution intermediate steps.</li>
                                    </ul>
                                    </p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/to_higher_3d.png" alt="blind-date"
                                        width="100%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="" target="_blank">
                                            <papertitle>3d Topology Optimization
                                            </papertitle>
                                        </a>
                                        <br>
                                    </p>
                                    <p>We built a multifidelity dataset of 300K optimized topologies with constraints.
                                    <ul>
                                        <li>150K beams.</li>
                                        <li>100K plates.</li>
                                        <li>50K l-shapes.</li>
                                    </ul>
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Teaching</heading>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>

                            <tr>
                                <td width="25%"><img src="./assets/images/dtu_teaching.png" alt="blind-date"
                                        width="50%"></td>
                                <td width="75%" valign="top">
                                    <p> &#x2022;
                                        <a href="https://kurser.dtu.dk/course/2020-2021/02456?menulanguage=en"
                                            target="_blank">
                                            <papertitle>Course 02456 Deep learning
                                            </papertitle>
                                        </a>
                                        (Fall 2020)
                                    </p>
                                    <p> &#x2022;
                                        <a href="https://kurser.dtu.dk/course/2021-2022/02477?menulanguage=en"
                                            target="_blank">
                                            <papertitle>Course 02477 Bayesian Machine Learning
                                            </papertitle>
                                        </a>
                                        (Spring 2021)
                                    </p>
                                    <p> &#x2022;
                                        <a href="https://kurser.dtu.dk/course/2021-2022/02460?menulanguage=en"
                                            target="_blank">
                                            <papertitle>Course 02460 Advanced Machine Learning
                                            </papertitle>
                                        </a>
                                        (Spring 2022)
                                    </p>
                                    <p> &#x2022;
                                        <a href="https://kurser.dtu.dk/course/2022-2023/02456?menulanguage=en"
                                            target="_blank">
                                            <papertitle>Course 02456 Deep learning
                                            </papertitle>
                                        </a>
                                        (Fall 2022)
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Patents</heading>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>

                            <!-- <tr>
                <td width="25%"><img src="./assets/images/consistency_ta.png" alt="blind-date" width="100%"></td>
                <td width="75%" valign="top">
                    <p>
                        <a href="">
                            <papertitle>Method and Apparatus to Learn Generative Optimization Models
                            </papertitle>
                        </a>
                        <br>
                        Giorgio Giannone, Akash Srivastava, Faez Ahmed
                        <br>
                        <em>filing</em>, 2023
                        <br>
                    </p>
                    <p></p>
                </td>
            </tr>

            <tr>
                <td width="25%"><img src="./assets/images/constraint_satisfaction_blocks.png" alt="blind-date" width="100%"></td>
                <td width="75%" valign="top">
                    <p>
                        <a href="">
                            <papertitle>Constraint Satisfaction in Generative AI using Negative Data
                            </papertitle>
                        </a>
                        <br>
                        Akash Srivastava, Giorgio Giannone, Faez Ahmed
                        <br>
                        <em>filing</em>, 2023
                        <br>
                    </p>
                    <p></p>
                </td>
            </tr> -->

                            <tr>
                                <td width="25%"><img src="./assets/images/pred_common1.png" alt="blind-date"
                                        width="100%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <a href="https://patents.google.com/patent/US11263756B2/en">
                                            <papertitle>Method and apparatus for semantic segmentation and depth
                                                completion using a convolutional neural network
                                            </papertitle>
                                        </a>
                                        <br>
                                        Boris Chidlovskii,
                                        Giorgio Giannone
                                        <br>
                                        <em>US Patent US11263756B2</em>, 2022
                                        <br>
                                    </p>
                                    <p></p>
                                </td>
                            </tr>

                        </tbody>
                        <tbody>
                        </tbody>
                    </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                        <tbody>
                            <tr>
                                <td>
                                    <heading>Theses</heading>
                                </td>

                            </tr>
                        </tbody>
                        <tbody>

                            <tr>
                                <td width="25%"><img src="./assets/images/pred_common.png" alt="blind-date"
                                        width="100%"></td>
                                <td width="75%" valign="top">
                                    <p>
                                        <papertitle>Learning Common Representation for Scene Understanding
                                        </papertitle>
                                        <br>
                                        Giorgio Giannone
                                        <br>
                                        <em>Master's Thesis, Data Science, Sapienza University of Rome</em>, 2018
                                        <br>
                                    </p>
                                    <p></p>
                                </td>
                            </tr>

                            <tr>
                                <td width="25%"><img src="./assets/images/bubble.png" alt="blind-date" width="100%">
                                </td>
                                <td width="75%" valign="top">
                                    <p>
                                        <papertitle>Bubble Dynamics in Turbulent Shear Flows
                                        </papertitle>
                                        <br>
                                        Giorgio Giannone
                                        <br>
                                        <em>Master's Thesis, Mechanical Engineering, Sapienza University of Rome</em>,
                                        2016
                                        <br>
                                    </p>
                                    <p></p>
                                </td>
                            </tr>
                        </tbody>
                        <tbody>
                        </tbody>
                    </table>

                </td>
            </tr>
        </tbody>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
            <tr>
                <td>
                    <br>
                    <p align="right">
                        <font size="2">
                            <a href="https://people.eecs.berkeley.edu/~barron/" target="_blank">the original</a>
                        </font>
                    </p>
                </td>
            </tr>
        </tbody>
    </table>

</body>

</html>